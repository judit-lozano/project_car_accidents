{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08940527",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b6aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from dython.nominal import associations\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import Counter\n",
    "import category_encoders as ce\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02c43f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nos guardamos la tabla a CSV\n",
    "#df_data.to_csv('datos/df_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b5381d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_MNTH</th>\n",
       "      <th>C_WDAY</th>\n",
       "      <th>C_HOUR</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>V_TYPE</th>\n",
       "      <th>P_SAFE</th>\n",
       "      <th>V_YEAR</th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>1990</td>\n",
       "      <td>1999</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1987</td>\n",
       "      <td>1999</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1986</td>\n",
       "      <td>1999</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1984</td>\n",
       "      <td>1999</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1991</td>\n",
       "      <td>1999</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C_MNTH  C_WDAY  C_HOUR  C_RCFG  C_WTHR  C_RSUR  C_RALN  C_TRAF  V_TYPE  \\\n",
       "0       1       1      20      50       1       5       3       3       6   \n",
       "1       1       1      20      50       1       5       3       3       1   \n",
       "2       1       1       8      50       5       3       6      18       1   \n",
       "3       1       1      17      56       1       2       1       1       1   \n",
       "4       1       1      17      56       1       2       1       1       1   \n",
       "\n",
       "   P_SAFE  V_YEAR  C_YEAR  P_AGE  P_SEX  TARGET  \n",
       "0      50    1990    1999     41      0       0  \n",
       "1      50    1987    1999     19      0       0  \n",
       "2      50    1986    1999     46      0       0  \n",
       "3      50    1984    1999     28      0       0  \n",
       "4      50    1991    1999     21      0       0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leemos nuestra tabla de nuevo\n",
    "df_data = pd.read_csv('datos/df_data.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03eab3a9-6ffd-4d30-87d0-cd656b78908f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_MNTH    int64\n",
       "C_WDAY    int64\n",
       "C_HOUR    int64\n",
       "C_RCFG    int64\n",
       "C_WTHR    int64\n",
       "C_RSUR    int64\n",
       "C_RALN    int64\n",
       "C_TRAF    int64\n",
       "V_TYPE    int64\n",
       "P_SAFE    int64\n",
       "V_YEAR    int64\n",
       "C_YEAR    int64\n",
       "P_AGE     int64\n",
       "P_SEX     int64\n",
       "TARGET    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c180e-38ec-4504-b8ce-e7a02dbc635e",
   "metadata": {},
   "source": [
    "### Codificación de las variables\n",
    "Applicaremos la siguiente codificación según grupo de variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0c61da22-e2d6-4040-9a69-9bf9220d42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grupos select_dtypesn tipo de encoding a realizar\n",
    "numeric_features = [\"V_YEAR\", 'C_YEAR', \"P_AGE\"] \n",
    "cat_features = list(set(df_data.drop('TARGET', axis=1).columns)-set(numeric_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98b50bbc-f3f7-45b8-9d77-00591e85099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[cat_features] = df_data[cat_features].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bed30efb-6f6b-4ad4-8575-74e8cbd00eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_MNTH    object\n",
       "C_WDAY    object\n",
       "C_HOUR    object\n",
       "C_RCFG    object\n",
       "C_WTHR    object\n",
       "C_RSUR    object\n",
       "C_RALN    object\n",
       "C_TRAF    object\n",
       "V_TYPE    object\n",
       "P_SAFE    object\n",
       "V_YEAR     int64\n",
       "C_YEAR     int64\n",
       "P_AGE      int64\n",
       "P_SEX     object\n",
       "TARGET     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "492d34ea-e985-429d-8ed9-ed5dc0494fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos train y target\n",
    "target = df_data[['TARGET']]\n",
    "train = df_data.drop('TARGET', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "76f1277e-1c5b-47d4-a5c5-75a55baa885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_MNTH</th>\n",
       "      <th>C_WDAY</th>\n",
       "      <th>C_HOUR</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>V_TYPE</th>\n",
       "      <th>P_SAFE</th>\n",
       "      <th>V_YEAR</th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>P_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>1990</td>\n",
       "      <td>1999</td>\n",
       "      <td>41</td>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.032684</td>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>1987</td>\n",
       "      <td>1999</td>\n",
       "      <td>19</td>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.016234</td>\n",
       "      <td>0.030981</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>1986</td>\n",
       "      <td>1999</td>\n",
       "      <td>46</td>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>1984</td>\n",
       "      <td>1999</td>\n",
       "      <td>28</td>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013036</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>0.010621</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.012630</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.012319</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>1991</td>\n",
       "      <td>1999</td>\n",
       "      <td>21</td>\n",
       "      <td>0.018556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C_MNTH    C_WDAY    C_HOUR    C_RCFG    C_WTHR    C_RSUR    C_RALN  \\\n",
       "0  0.013036  0.013388  0.018474  0.010050  0.013724  0.016415  0.032684   \n",
       "1  0.013036  0.013388  0.018474  0.010050  0.013724  0.016415  0.032684   \n",
       "2  0.013036  0.013388  0.009810  0.010050  0.021564  0.016234  0.030981   \n",
       "3  0.013036  0.013388  0.010621  0.019557  0.013724  0.012630  0.012028   \n",
       "4  0.013036  0.013388  0.010621  0.019557  0.013724  0.012630  0.012028   \n",
       "\n",
       "     C_TRAF    V_TYPE    P_SAFE  V_YEAR  C_YEAR  P_AGE     P_SEX  \n",
       "0  0.011866  0.020918  0.015462    1990    1999     41  0.018556  \n",
       "1  0.011866  0.012319  0.015462    1987    1999     19  0.018556  \n",
       "2  0.020896  0.012319  0.015462    1986    1999     46  0.018556  \n",
       "3  0.004503  0.012319  0.015462    1984    1999     28  0.018556  \n",
       "4  0.004503  0.012319  0.015462    1991    1999     21  0.018556  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Catboost encoding\n",
    "catboost = ce.CatBoostEncoder()\n",
    "catboost.fit(train, target)\n",
    "df_coded = catboost.transform(train)\n",
    "df_coded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14e87c-3a37-4fdf-81dc-f785e78df6e0",
   "metadata": {},
   "source": [
    "### Escalado de las variables\n",
    "Aunque en algunos salgoritmos no sea necesario el escalado de variables, pasaremos a realizarlo en este punto para trabajar con los datos en formato unificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b372f630-319e-492a-9b1e-39990ecce867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_MNTH</th>\n",
       "      <th>C_WDAY</th>\n",
       "      <th>C_HOUR</th>\n",
       "      <th>C_RCFG</th>\n",
       "      <th>C_WTHR</th>\n",
       "      <th>C_RSUR</th>\n",
       "      <th>C_RALN</th>\n",
       "      <th>C_TRAF</th>\n",
       "      <th>V_TYPE</th>\n",
       "      <th>P_SAFE</th>\n",
       "      <th>V_YEAR</th>\n",
       "      <th>C_YEAR</th>\n",
       "      <th>P_AGE</th>\n",
       "      <th>P_SEX</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.41349</td>\n",
       "      <td>-0.504111</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>-0.605457</td>\n",
       "      <td>-0.246324</td>\n",
       "      <td>0.987280</td>\n",
       "      <td>2.518029</td>\n",
       "      <td>-0.363466</td>\n",
       "      <td>0.709934</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>-0.584604</td>\n",
       "      <td>-1.533381</td>\n",
       "      <td>-0.150771</td>\n",
       "      <td>0.81667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.41349</td>\n",
       "      <td>-0.504111</td>\n",
       "      <td>0.639472</td>\n",
       "      <td>-0.605457</td>\n",
       "      <td>-0.246324</td>\n",
       "      <td>0.987280</td>\n",
       "      <td>2.518029</td>\n",
       "      <td>-0.363466</td>\n",
       "      <td>-0.251504</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>-0.692229</td>\n",
       "      <td>-1.533381</td>\n",
       "      <td>-0.896072</td>\n",
       "      <td>0.81667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.41349</td>\n",
       "      <td>-0.504111</td>\n",
       "      <td>-0.779007</td>\n",
       "      <td>-0.605457</td>\n",
       "      <td>2.041762</td>\n",
       "      <td>0.890469</td>\n",
       "      <td>2.281274</td>\n",
       "      <td>0.851024</td>\n",
       "      <td>-0.251504</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>-0.728104</td>\n",
       "      <td>-1.533381</td>\n",
       "      <td>0.018616</td>\n",
       "      <td>0.81667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.41349</td>\n",
       "      <td>-0.504111</td>\n",
       "      <td>-0.646253</td>\n",
       "      <td>0.668421</td>\n",
       "      <td>-0.246324</td>\n",
       "      <td>-1.036199</td>\n",
       "      <td>-0.353054</td>\n",
       "      <td>-1.353824</td>\n",
       "      <td>-0.251504</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>-0.799854</td>\n",
       "      <td>-1.533381</td>\n",
       "      <td>-0.591176</td>\n",
       "      <td>0.81667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.41349</td>\n",
       "      <td>-0.504111</td>\n",
       "      <td>-0.646253</td>\n",
       "      <td>0.668421</td>\n",
       "      <td>-0.246324</td>\n",
       "      <td>-1.036199</td>\n",
       "      <td>-0.353054</td>\n",
       "      <td>-1.353824</td>\n",
       "      <td>-0.251504</td>\n",
       "      <td>0.074408</td>\n",
       "      <td>-0.548729</td>\n",
       "      <td>-1.533381</td>\n",
       "      <td>-0.828318</td>\n",
       "      <td>0.81667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C_MNTH    C_WDAY    C_HOUR    C_RCFG    C_WTHR    C_RSUR    C_RALN  \\\n",
       "0 -1.41349 -0.504111  0.639472 -0.605457 -0.246324  0.987280  2.518029   \n",
       "1 -1.41349 -0.504111  0.639472 -0.605457 -0.246324  0.987280  2.518029   \n",
       "2 -1.41349 -0.504111 -0.779007 -0.605457  2.041762  0.890469  2.281274   \n",
       "3 -1.41349 -0.504111 -0.646253  0.668421 -0.246324 -1.036199 -0.353054   \n",
       "4 -1.41349 -0.504111 -0.646253  0.668421 -0.246324 -1.036199 -0.353054   \n",
       "\n",
       "     C_TRAF    V_TYPE    P_SAFE    V_YEAR    C_YEAR     P_AGE    P_SEX  TARGET  \n",
       "0 -0.363466  0.709934  0.074408 -0.584604 -1.533381 -0.150771  0.81667       0  \n",
       "1 -0.363466 -0.251504  0.074408 -0.692229 -1.533381 -0.896072  0.81667       0  \n",
       "2  0.851024 -0.251504  0.074408 -0.728104 -1.533381  0.018616  0.81667       0  \n",
       "3 -1.353824 -0.251504  0.074408 -0.799854 -1.533381 -0.591176  0.81667       0  \n",
       "4 -1.353824 -0.251504  0.074408 -0.548729 -1.533381 -0.828318  0.81667       0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(df_coded)\n",
    "train_scaled = pd.DataFrame(scaler.transform(df_coded), columns=df_coded.columns, index=df_coded.index)\n",
    "df_scaled = pd.concat([train_scaled, target], axis=1).reset_index(drop=True)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b48a2c51-e00a-4167-8caf-57c1d9491b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv('datos/df_coded_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ddea2-05c2-41cb-8da2-34926d7877a4",
   "metadata": {},
   "source": [
    "### Dividimos el dataset en train y test\n",
    "Dividimos el dataset en train y test manteniendo la proporción de la variable objetivo en las dos partes (separación estratificada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "141c6987-c52c-45c6-b946-cf7b25539c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('TARGET',axis=1)\n",
    "y = df_scaled['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "107d55ea-663a-4787-8927-9bfb1fe1df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, shuffle=True, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "388e3b28-a224-4289-8e07-028a74e465c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.985431\n",
      "1    0.014569\n",
      "Name: TARGET, dtype: float64\n",
      "0    0.985432\n",
      "1    0.014568\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#comprobación de la estratificación\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79bcec-4f2b-4222-8520-1227e18eb8ca",
   "metadata": {},
   "source": [
    "### Problema de desbalanceo de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd704596-cb54-466b-9575-055ed16f01be",
   "metadata": {},
   "source": [
    "Para solventar este problema probaremos con la técnica SMOTE y con la técnica SMOTE Tomeklinks y comprobaremos cuál nos dá mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abe7f7-d5ff-474d-8a37-f1e3912f7e0f",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "SMOTE realiza un oversample de la clase minoritaria segun la configuracion que le demos (Ej: strategy, k-values). Por defecto, el K-value es 5. Sin embargo, procederemos a realizar una busqueda de K-values con un grid entre un rago de valores de entre 1 y 7 para intentar optimizar el sintetizado de la clase minoritaria con vistas a generar un resultado más apropiado para el modelo que utilicemos.\n",
    "\n",
    "Por ejemplo, para un LogisticRegression, procederemos a analizar cual serían el K_value en SMOTE que nos proporcionaría el mejor resultado.\n",
    "\n",
    "### Resultados del modelo LogisticRegression sin aplicar SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d9f70d0-d2c8-4488-a4a7-6309bc6e6b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    773779\n",
      "           1       0.20      0.00      0.00     11439\n",
      "\n",
      "    accuracy                           0.99    785218\n",
      "   macro avg       0.59      0.50      0.50    785218\n",
      "weighted avg       0.97      0.99      0.98    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# logistic regression object\n",
    "lr = LogisticRegression()\n",
    " \n",
    "# train the model on train set\n",
    "lr.fit(X_train, y_train.ravel())\n",
    " \n",
    "predictions = lr.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a3d528b-8eef-4161-81c0-f3c214cb2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_evaluation(y_true, y_pred):\n",
    "    results_dict = {'accuracy': accuracy_score(y_true, y_pred),\n",
    "                    'recall': recall_score(y_true, y_pred),\n",
    "                    'precision': precision_score(y_true, y_pred),\n",
    "                    'f1_score': f1_score(y_true, y_pred)}\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a92e1144-3fe3-4aad-ace7-b1dac5742a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9853989592699097,\n",
       " 'recall': 0.0007867820613690008,\n",
       " 'precision': 0.20454545454545456,\n",
       " 'f1_score': 0.0015675346163894451}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr)\n",
    "print(\"model score: %.3f\" % lr.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27396406-1a61-48c0-a27e-212c426bd39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51a9741e-1b75-40be-9129-728e3f38e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': 45758\n",
      "Before OverSampling, counts of label '0': 3095110 \n",
      "\n",
      "After OverSampling, the shape of train_X: (6190220, 14)\n",
      "After OverSampling, the shape of train_y: (6190220,) \n",
      "\n",
      "After OverSampling, counts of label '1': 3095110\n",
      "After OverSampling, counts of label '0': 3095110\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n",
    " \n",
    "# import SMOTE module from imblearn library\n",
    "# pip install imblearn (if you don't have imblearn in your system)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    " \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    " \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f738d07f-61f8-43a6-8afc-a0750ddb2444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.72      0.83    773779\n",
      "           1       0.03      0.67      0.06     11439\n",
      "\n",
      "    accuracy                           0.72    785218\n",
      "   macro avg       0.51      0.69      0.45    785218\n",
      "weighted avg       0.98      0.72      0.82    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(X_train_res, y_train_res.ravel())\n",
    "predictions = lr1.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc487c90-2a4d-408d-970b-fd89423741a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7191773494749228,\n",
       " 'recall': 0.6692018533088556,\n",
       " 'precision': 0.034116535489219085,\n",
       " 'f1_score': 0.06492322436465564}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr)\n",
    "print(\"model score: %.3f\" % lr.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b265f3fd-477c-41bc-96cc-bfaddc1c473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=1, Mean ROC AUC: 0.780\n",
      "> k=2, Mean ROC AUC: 0.781\n",
      "> k=3, Mean ROC AUC: 0.781\n",
      "> k=4, Mean ROC AUC: 0.782\n",
      "> k=5, Mean ROC AUC: 0.782\n",
      "> k=6, Mean ROC AUC: 0.783\n",
      "> k=7, Mean ROC AUC: 0.783\n"
     ]
    }
   ],
   "source": [
    "# grid search k value for SMOTE oversampling for imbalanced classification\n",
    "import lightgbm as lgb\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "k_values = [7]\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "model = lgb.LGBMClassifier()\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "39eb9685-21fc-465c-95a0-e80fbd1f7ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n"
     ]
    }
   ],
   "source": [
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f135547b-77b9-4bd7-a824-1b6fdee7655d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=7, Mean ROC AUC: 0.763\n"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "k_values = [7]\n",
    "\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model = LogisticRegression()\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "045f9d12-8677-4446-8019-1f06c883c619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=7, Mean ROC AUC: 0.763\n"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "k_values = [7]\n",
    "\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model = LogisticRegression()\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.1)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2246e04e-6f6a-45fc-9a2b-46a03bd35ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "350cf483-d190-4b1f-9da3-4cb44728c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95    773779\n",
      "           1       0.06      0.39      0.10     11439\n",
      "\n",
      "    accuracy                           0.90    785218\n",
      "   macro avg       0.52      0.65      0.52    785218\n",
      "weighted avg       0.98      0.90      0.93    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3919563d-6450-4e3e-b4ec-a2ef22ff472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8977048412033346,\n",
       " 'recall': 0.3916426261036804,\n",
       " 'precision': 0.057550260132314214,\n",
       " 'f1_score': 0.10035392679539447}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0577e706-c3b2-4f5b-bc3a-a7470afd32cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 1031703, 1: 928533})\n"
     ]
    }
   ],
   "source": [
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.3, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.9)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e4a9a6ce-95e9-4ef8-878f-0a09893bfb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eef84925-d2e8-4861-95b2-90abad18479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.76      0.86    773779\n",
      "           1       0.04      0.63      0.07     11439\n",
      "\n",
      "    accuracy                           0.76    785218\n",
      "   macro avg       0.52      0.69      0.47    785218\n",
      "weighted avg       0.98      0.76      0.85    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f569d408-b6d4-4e04-aeb8-ca5f573048e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7601685137121156,\n",
       " 'recall': 0.6256665792464376,\n",
       " 'precision': 0.0374329872643113,\n",
       " 'f1_score': 0.07063967547400732}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b397991-d70f-4f32-857a-07af47c6eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 1547555})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.5, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "49e6c72b-6bfa-416d-98b2-b7b1a60dbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95    773779\n",
      "           1       0.06      0.39      0.10     11439\n",
      "\n",
      "    accuracy                           0.90    785218\n",
      "   macro avg       0.52      0.65      0.52    785218\n",
      "weighted avg       0.98      0.90      0.93    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2c611212-043a-4cf6-9db2-d8fc9d7dac69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8974310318917804,\n",
       " 'recall': 0.3926916688521724,\n",
       " 'precision': 0.05752779058449874,\n",
       " 'f1_score': 0.10035409894663941}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "48401e5f-0144-4aa9-84d0-8799574807c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 309511})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.1)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "83f55810-82f3-403b-b727-3d1b3d2f05cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    773779\n",
      "           1       0.14      0.07      0.10     11439\n",
      "\n",
      "    accuracy                           0.98    785218\n",
      "   macro avg       0.56      0.53      0.54    785218\n",
      "weighted avg       0.97      0.98      0.98    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "98524c0e-0195-43f1-9742-d6bc99f28c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9801329057662967,\n",
       " 'recall': 0.07159716758457907,\n",
       " 'precision': 0.14123124676668392,\n",
       " 'f1_score': 0.09502262443438915}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71ac35-86d6-4136-8b5e-8cb73f88b837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9a5a6bcd-e8f2-4991-9024-d502fc5f8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 1547555, 1: 309511})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bde4425e-2d22-4dd0-a96c-1957d67d50ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    773779\n",
      "           1       0.10      0.18      0.13     11439\n",
      "\n",
      "    accuracy                           0.97    785218\n",
      "   macro avg       0.55      0.58      0.56    785218\n",
      "weighted avg       0.97      0.97      0.97    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "68553299-12d3-49a2-8b80-c115e14d7950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9660450983039105,\n",
       " 'recall': 0.17571466037241018,\n",
       " 'precision': 0.10445356753105026,\n",
       " 'f1_score': 0.13102144579883973}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "272de775-dbff-450d-9a36-cd57cc1def6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=7, Mean ROC AUC: 0.763\n"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "\n",
    "model = LogisticRegression()\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('> k=%d, Mean ROC AUC: %.3f' % (k, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c0cbc-7c98-4e95-9c66-3accf533e12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14b9e45b-223d-4918-b996-1fbf97a65a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 619022})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.2, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ca551b48-5c0d-4a5c-bded-77bf470715b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98    773779\n",
      "           1       0.10      0.17      0.13     11439\n",
      "\n",
      "    accuracy                           0.97    785218\n",
      "   macro avg       0.55      0.58      0.56    785218\n",
      "weighted avg       0.97      0.97      0.97    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6a2df2bf-32a3-4ec2-acca-f644e4b3238c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9661113219513562,\n",
       " 'recall': 0.1748404580820002,\n",
       " 'precision': 0.10432423973710292,\n",
       " 'f1_score': 0.1306762495916367}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2daac-cfe9-4595-afb5-821cc21084c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a81227f6-72bc-4ecd-a222-9202ccb604e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 928533})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.3, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.3)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c0eed12-cf7d-43c0-9f12-e42d8f082a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97    773779\n",
      "           1       0.08      0.25      0.12     11439\n",
      "\n",
      "    accuracy                           0.95    785218\n",
      "   macro avg       0.53      0.60      0.55    785218\n",
      "weighted avg       0.98      0.95      0.96    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b5c91dae-e064-4939-933d-f97df3f9957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "model score: 0.948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9476272831239223,\n",
       " 'recall': 0.24958475391205526,\n",
       " 'precision': 0.08066111032631727,\n",
       " 'f1_score': 0.12191997266942818}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "88f56773-078f-4971-968f-6c2e1808b103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=7, Mean ROC AUC: 0.763\n"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "k_values = [7]\n",
    "\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model = LogisticRegression()\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f8aa6-9a36-4042-84e2-9766e93f00ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b8558dd4-fc5e-445c-b7d9-59e8c833784d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 619022})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.2, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81a0adae-d855-4225-abb3-b9aefe5d2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:40:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    773779\n",
      "           1       0.70      0.00      0.01     11439\n",
      "\n",
      "    accuracy                           0.99    785218\n",
      "   macro avg       0.84      0.50      0.50    785218\n",
      "weighted avg       0.98      0.99      0.98    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = xgb.XGBClassifier()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "47cf1a82-8587-4429-94b9-904957547df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "model score: 0.985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9854702770440821,\n",
       " 'recall': 0.0045458519101320045,\n",
       " 'precision': 0.7027027027027027,\n",
       " 'f1_score': 0.00903326674194389}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cef56619-041e-4bad-a622-b8a0862e441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:01:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:08:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:14:44] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:20:57] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "> k=7, Mean ROC AUC: 0.790\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2d058-5bad-4c97-a2d5-77560569ec4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add79aa3-de65-444e-8bc5-4dbbf414ddb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "40551589-a554-4d16-a9b6-9fc889431d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n",
      "Counter({0: 3095110, 1: 619022})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Una vez que ya tienes el K_value\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.2, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.2)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X_train_sm, y_train_sm = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train_sm)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ffd17fcc-34de-4600-b0fc-6cc4b499c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99    773779\n",
      "           1       0.48      0.00      0.00     11439\n",
      "\n",
      "    accuracy                           0.99    785218\n",
      "   macro avg       0.73      0.50      0.50    785218\n",
      "weighted avg       0.98      0.99      0.98    785218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Probando el nuevo dataset con un logistic Regression\n",
    "lr2 = lgb.LGBMClassifier()\n",
    "lr2.fit(X_train_sm, y_train_sm.ravel())\n",
    "predictions = lr2.predict(X_test)\n",
    " \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c8d41f2a-e7bb-48ed-9a8a-a02554bccac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier()\n",
      "model score: 0.985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.985430797561951,\n",
       " 'recall': 0.0008742022904100009,\n",
       " 'precision': 0.47619047619047616,\n",
       " 'f1_score': 0.001745200698080279}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(lr2)\n",
    "print(\"model score: %.3f\" % lr2.score(X_test, y_test))\n",
    "print_binary_evaluation(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "164d0086-ca77-40f2-84c9-891012a677a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> k=7, Mean ROC AUC: 0.783\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "over = SMOTE(sampling_strategy=0.1, k_neighbors=7)\n",
    "under = RandomUnderSampler(sampling_strategy=0.1)\n",
    "steps = [('over', over), ('under', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "score = mean(scores)\n",
    "print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb93a4d1-bb5e-4b92-b9a9-003d85f20656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404927af-c002-4f6e-a016-010f5ea21ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845d888-c973-4299-b69b-22642f9cbeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c4e1ceed-c519-47f0-a5e8-93ac4b13017e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3954110982.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/yq/qscz1b2n6v96fd3jzykvyggm0000gn/T/ipykernel_9633/3954110982.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    model = lgb.LGBMClassifier()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#### grid search k value for SMOTE oversampling for imbalanced classification\n",
    "import lightgbm as lgb\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# values to evaluate\n",
    "k_values = [7]\n",
    "for k in k_values:\n",
    "# define pipeline\n",
    "    model = lgb.LGBMClassifier()\n",
    "    over = SMOTE(sampling_strategy=0.1, k_neighbors=k)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('over', over), ('under', under), ('model', model)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # evaluate pipeline\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    score = mean(scores)\n",
    "    print('> k=%d, Mean ROC AUC: %.3f' % (k, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3d59c-69df-4747-a887-04b524941d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f9c5826-9b86-4e71-a540-363fae1ef3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 45758})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yq/qscz1b2n6v96fd3jzykvyggm0000gn/T/ipykernel_9633/643806890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0moversample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#aquí le especifíco el ratio que quiero de la clase minoritaria\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# uso random_state para que los datos puedan ser reproducidos en otro ordenador usando el mismo código.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moversample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m# summarize the new class distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    181\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    182\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "oversample = SMOTE(sampling_strategy=0.35, random_state=0) #aquí le especifíco el ratio que quiero de la clase minoritaria\n",
    "# uso random_state para que los datos puedan ser reproducidos en otro ordenador usando el mismo código.\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f486611-274a-44e1-8d89-dbaa5c2d60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pickle', 'wb') as f:\n",
    "    pickle.dump([X_train, y_train, X_test, y_test], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e1761-6a0e-41b7-9424-e055e91097a5",
   "metadata": {},
   "source": [
    "### Escalado de las variables\n",
    "Aunque en algunos salgoritmos no sea necesario el escalado de variables, pasaremos a realizarlo en este punto para trabajar con los datos en formato unificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626db97-87f1-4c4d-b22a-200de57b0200",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230509a8-6890-4a2f-bea5-cea01269dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "print(rfc)\n",
    "print(\"model score: %.3f\" % rfc.score(X_test_pca, y_test))\n",
    "y_pred = rfc.predict(X_test_pca)\n",
    "print_binary_evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb8d2e-e24e-4db5-aba2-6ca8d9bb75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_scaled.pickle', 'wb') as f:\n",
    "    pickle.dump([X_train_scaled, y_train, X_test_scaled, y_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4822af-aadc-4168-9353-55b2af18c783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48443a0e-fc06-4f67-8ebd-d4b55936b4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0d49c-0acf-44ca-9f76-ede9b6922008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "599bfeb0-cb5f-469a-ba9d-5edf001dff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_scaled.pickle', 'rb') as f:\n",
    "    X_train_scaled, y_train, X_test_scaled, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fca930-81e1-4fa7-88e6-612357bee5c3",
   "metadata": {},
   "source": [
    "### SMOTE and Tomek Links Undersampling\n",
    "SMOTE realiza un oversample de la clase minoritaria como hemos visto anteriormente. Tome Links identifica partes de observaciones cercanas en el dataset de diferentes clases y elimina uno o los dos elementos según especifiquemos. El objetivo de Tome Links es hacer que el límite que define al conjunto de una clase y al conjunto de la otra sea menos ambiguo. A través de la funcion SMOTETomek se combinan ambas técnicas.\n",
    "En nuestro caso configuraremos Tomek para eliminar los links de la clase mayoritaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a2f07-bab8-4ad1-8aa3-7b047f6aa87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 3095110, 1: 1083288})\n"
     ]
    }
   ],
   "source": [
    "# borderline-SMOTE for imbalanced dataset\n",
    "from collections import Counter\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "# summarize class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "oversample = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'), random_state=0) \n",
    "X_train_tk, y_train_tk = oversample.fit_resample(X_train_scaled, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95b4d7-15ee-47d7-9f72-3ab8242d0447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db0e6bc0-0858-46d6-9b0a-df5611092b68",
   "metadata": {},
   "source": [
    "### Escalado de las variables\n",
    "Volvemos a realizar el escalado después de aplicar el SMOTETomek y nos guardamos las variables para poder contrastar en el siguiente cuaderno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91923288-8bf2-4af1-93c9-cde5e47b0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(X_train_tk)\n",
    "X_train_scaled_tk = pd.DataFrame(scaler.transform(X_train_tk), columns=X_train_tk.columns, index=X_train_tk.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351518a1-9e1d-46bc-bb59-3d60e25436a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_scaled_tk.pickle', 'wb') as f:\n",
    "    pickle.dump([X_train_scaled_tk, y_train_tk, X_test_scaled, y_test], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beeb7fc-0973-4e4a-bd39-24161eba1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('train.pickle', 'rb') as f:\n",
    " #   X_train, y_train, X_test, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcca5f1-5df3-4a14-b05c-e0a30eb133d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
